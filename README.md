# Lunar Lander - Deep Reinforcement Learning
Solved OpenAI's Continuous Lunar Lander with a an average reward of 200+ over the last 100 episodes at episode 493. Other Data Science & Machine Learning projects can be found at the [main GitHub repo](https://github.com/SR14).

## Getting Started

1. **[Final Report](https://github.com/SR14/LunarLander-DeepRL/blob/master/LunarLanderReport.pdf)**


2. All corresponding algorithmic components can be found [here](https://github.com/SR14/LunarLander-DeepRL/tree/master/agents). More specifically, the corresponding components of the algorithm are memory.py for the PER buffer; noise.py for Gaussian noise added to the learning stage; actor.py holds the actor network architecture; critic.py holds critic network architecture; and the agent.py holds the compiled DDPG algorithm with a third critic and noise addition to target action.


3. OpenAI's "LunarLanderContinuous-v2" environment implementation can be seen in this [Python script](https://github.com/SR14/LunarLander-DeepRL/blob/master/task.py). 


4. The Jupyter Notebook used to compile the Python scripts can be found [here](https://github.com/SR14/LunarLander-DeepRL/blob/master/LunarLanderContinuous-v2.ipynb)


5. Test episode's data can be found in the [data.txt](https://github.com/SR14/LunarLander-DeepRL/blob/master/data.txt) file, and the test episode gif can be found in LunarLander.gif

Looking for feedback on how the model could be improved! (:
